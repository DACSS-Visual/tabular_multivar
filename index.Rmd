<br> 
<center><img src="https://i.imgur.com/AbCCpQO.png" width="700"></center>


_____

<a id='TOC'></a>


# Tabular data - Multivariate data

_____

1. [Introduction](#part1)

2. [Averaging](#part2)

3. [Dimensionality Reduction](#part3)





_____

```{r klippy, echo=FALSE, include=TRUE, warning=FALSE, message=FALSE}
klippy::klippy(position = c('top', 'right'))
```



We collect multiple variables for a particular purpose, knowing that social complexity can hardly be directly explained with bivariate or univariate approaches. As it is difficult to visualize information with high dimensional data; you should consider summarising all these variable into a simpler form.

Let me start from the simplest.

_____

<a id='part1'></a>

# Introduction

This time, I will use the [data about city safety](https://safecities.economist.com/):

```{r, eval=TRUE, message=FALSE}
# clean memory
rm(list = ls()) 

# location of the data
link="https://github.com/DACSS-Visual/tabular_multivar/raw/main/data/safeCitiesIndexAll.xlsx"

# 'rio' can be used to import EXCEL files:
library(rio)
safe=import(link)
```


These several variables are telling us information about the safety levels of some cities in the world, and are related to **D**_igital_, **H**_ealth_, **I**_nfrastructure_, and **P**_ersonal_ dimensions. For each of these dimensions, there are measures of actions taken (**In**), and results obtained (**Out**). We have 49 variables.


[Go to table of contents.](#TOC)

________

<a id='part11'></a>

## Re introducing heatmap

Would making a plot of 49 variables  be a good idea? A **heatmap** is the usual answer.

Making a **heatmap** in _ggplot2_ requires a file in a particular _shape_, known as the **long format**.

The data frame _safe_ is in **wide format**, that is, one observation per row (the most usual format):

```{r, eval=TRUE}
head(safe)
```

This is how we produce a **long format**:

```{r, eval=TRUE}
library(reshape2)

safeL=melt(safe, # all the data
           id.vars = 'city') # unique id per row
head(safeL)

```

The _melt function_ changed the direction of the data: the variables with the values were sent into rows, and the values are now to their right.

Now, the _heatmap_ using this format:

```{r, eval=TRUE}
library(ggplot2)

base = ggplot(data = safeL, 
              aes(x = variable,
                  y =city)) 

heat1= base +  geom_tile(aes(fill = value)) 
heat1
```






As interesting emerges, let's also reorder rows (cities) and rows (indicators) by the median:

```{r, eval=TRUE}
base= ggplot(data = safeL, aes(x = reorder(variable, 
                                           value, median),
                               y =reorder(city,
                                          value, median)))
heat2= base + geom_tile(aes(fill = value)) 

heat2
```

Here you can see what rows have higher or lower colors on what set of variables. You can add color pallette:

```{r, eval=TRUE}
#inverse color -1
heat2_recolor = heat2 +
                scale_fill_gradient(low = 'grey30',
                                    high = "grey90"
                                    )
heat2_recolor
```

The column names need some work:

```{r, eval=TRUE}
heat2_axisGood= heat2_recolor + 
                theme(axis.text.x = element_text(angle = 60, 
                                         hjust = 1,
                                         size = 6))

heat2_axisGood
```

[Go to table of contents.](#TOC)

________

<a id='part2'></a>

# Averaging

This is still hard to read. An alternative could be to average each dimension. Let me show you this example:

a. Variables you need to average: columns with the text 'D_In_': 

```{r, eval=TRUE}
library(magrittr)
#notice I do not need the 'city':
safe[,c(grep("D_In_", names(safe) ))]%>%head()
```

b. Compute and save the average **per row**:

```{r, eval=TRUE}


#averaging only numbers, as 'city' is not in data:
apply(safe[,c(grep("D_In_",names(safe) ))], #data
      1, #by row
      mean)%>% #function to apply by row to data
         round(2) # round the result

```

c. Create that column:

```{r, eval=TRUE}
safe$Digi_I=apply(safe[,c(grep("D_In_",names(safe) ))],1,mean)%>%round(2)
```

Now let's do the rest:

```{r, eval=TRUE}
safe$Digi_O=apply(safe[,c(grep("D_Out_",names(safe) ))],1,mean)%>%round(2)

safe$Health_I=apply(safe[,c(grep("H_In_",names(safe) ))],1,mean)%>%round(2)

safe$Health_O=apply(safe[,c(grep("H_Out_", names(safe) ))],1,mean)%>%round(2)

safe$Infr_I=apply(safe[,c(grep("I_In_", names(safe) ))],1,mean)%>%round(2)

safe$Infr_O=apply(safe[,c(grep("I_Out_", names(safe) ))],1,mean)%>%round(2)

safe$Perso_I=apply(safe[,c(grep("P_In_", names(safe) ))],1,mean)%>%round(2)

safe$Perso_O=apply(safe[,c(grep("P_Out_", names(safe) ))],1,mean)%>%round(2)


```


Let's subset the previous data frame so that a new one has  all the **Input** variables:

```{r, eval=TRUE}
safeINS=safe[,c(1,grep("_I$", colnames(safe)))] # '$' for 'end with'.
head(safeINS)

```

Let's rename the vars in this data set:
```{r, eval=TRUE}
names(safeINS)=c("city",'DIGITAL','HEALTH','INFRASTR','PERSONAL')
```


Remember we need to reshape:

```{r, eval=TRUE}
safeINS_long=melt(safeINS,id.vars = 'city')
```

Let's redo our heat map:
```{r, eval=TRUE}
base= ggplot(data = safeINS_long, 
             aes(x = reorder(variable,
                             value, 
                             median),
                 y =reorder(city,
                            value, 
                            median)))

base + geom_tile(aes(fill = value)) + 
       scale_fill_gradient(low = 'grey90',
                           high = "grey50") +
       theme(axis.text.x = element_text(angle = 90,
                                        hjust = 1,
                                        size = 8),
             axis.text.y = element_text(size = 6))
```
[Go to table of contents.](#TOC)

________

<a id='part21'></a>

## The Radar

When you have this limited amount of variables, you may try a radar plot:


```{r, fig.width=15, fig.height=12, eval=TRUE}
library(ggforce)

base  = ggplot(safeINS_long, 
               aes(x = variable, 
                   y = value, 
                   group = city)) + #new
        geom_shape(fill = 'gray',
                     col='orange')

radar1 = base + coord_polar()


radar1_re = radar1 + facet_wrap(~reorder(city,-value, median),ncol = 10)


radar1_re = radar1_re + theme(axis.text.x = element_text(size = 8)) 

radar1_label = radar1_re + theme(legend.position="none",
                strip.text = element_text(size = 12, colour = 'blue')) #here!!!
radar1_label
```


You could add extra customization if wanted:

```{r, fig.width=15, fig.height=12, eval=TRUE}

### arguments
newBackGroundGrid=element_rect(fill = "white",
                         colour = "red",
                         linewidth = 0.5,
                         linetype = "dashed")

newBackLineGrid=element_line(linewidth = 1,
                      linetype = 'solid',
                      colour = "lightblue")

### more customization
radar1_label+ theme(panel.background = newBackGroundGrid,
             panel.grid.major = newBackLineGrid)
                        
```

The colors above **are not** the best choice, I just used them for you to notice where to make changes. Keep in mind that areas are difficult to compare, so the plots above might be used with care (show not all the cities?).


[Go to table of contents.](#TOC)

________

<a id='part22'></a>

## Simplifying the Radar


The idea behind the radar plot can be represented by simpler plots:

```{r}
ggplot(data=safeINS_long, 
       aes(x=reorder(city, value,median),
           y=value)) + theme_classic() +
    geom_point(shape=5)+
    geom_segment(aes(x=city,
                     y=0,
                     yend = value,
                     xend = city),
                 color='grey',linewidth=0.2) +
    facet_grid(~variable) + coord_flip() + 
    theme(axis.text.y = element_text(size = 5))
```

[Go to table of contents.](#TOC)

________

<a id='part3'></a>

# Dimensionality Reduction

Finally, let me produce a plot using all the input variables, but reducing their dimensionality combining **clustering** and **multidimensional scaling**.


You can use multidimensional scaling to represent **all the variables in a two dimensional plot**. This will create a **map** that will allow you to visualize "neighborhoods of similarity"  of the cases (cities). With clustering, you will use the variables (columns) to define homogeneous groups among the cases (rows).

Let's see:

a. Get all the **input** columns:

```{r, eval=TRUE}
allIN=safe[,c(grep("_In_", names(safe) ))]
names(allIN)
```

b. Add city names:

```{r, eval=TRUE}
rownames(allIN)=safe$city
```

c. Compute the distance among cases:

```{r, eval=TRUE}
dist_in_safe=dist(allIN) 
```

d. Compute clusters

With some many data, it would be useful to divide the cities into clusters. Let's decice based on the dendogram.

```{r}
plot(hclust(dist_in_safe, method = 'ward.D2'),cex=0.6)
```

We could ask for 5 clusters:

```{r}
library(factoextra)

res.agnes<- hcut(dist_in_safe, k = 5,hc_func='agnes',hc_method = "ward.D")

allIN$agnes=as.factor(res.agnes$cluster)
```



d. Get map using multidimensional scaling:
```{r, eval=TRUE}
theMap=cmdscale(dist_in_safe,k = 2)
head(theMap,10)
```

Add them to data frame
```{r, eval=TRUE}
#add to dataframe
allIN$dim1=theMap[,1]
allIN$dim2=theMap[,2]
```

Let plot the countries using dim1 and dim2 as coordinates:

```{r, eval=TRUE}

library(ggplot2)
base=ggplot(allIN,aes(x=dim1,y=dim2,
                       color=agnes,
                       label = rownames(allIN)))
cityPoints=base + geom_point() 
 
cityPoints + geom_text()

```

Let's use *ggrepel* to improve labelling:

```{r, eval=TRUE}
library(ggrepel)

cityPointsText=cityPoints + theme_void() +
               geom_text_repel(size=1.5,
                               max.overlaps = 20) 

cityPointsText

```


Would you like your own colors? ...becareful!
```{r, eval=TRUE}
cityPointsText+scale_color_manual(values = c("orange",'lightgreen','red','magenta','grey50'))
```

[Go to table of contents.](#TOC)

___________





